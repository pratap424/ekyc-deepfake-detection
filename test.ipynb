{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9e6c5d9-bb39-494e-a644-51d8a57f4e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n",
      "‚úÖ IdentityVerifierONNX loaded (InceptionResnetV1)\n",
      "‚úÖ LivenessDetector loaded (DeepPixBiS - Optimized)\n",
      "\n",
      "‚úÖ Webcam test: Take 2 photos of yourself\n",
      "Press 'C' to capture first photo\n",
      "Press 'C' again to capture second photo\n",
      "Press 'Q' to quit\n",
      "\n",
      "‚úÖ Captured photo 1\n",
      "‚úÖ Captured photo 2\n",
      "\n",
      "üîç Verifying identity...\n",
      "\n",
      "==================================================\n",
      "Match Score: 98.85%\n",
      "Same Person: True\n",
      "Threshold: 70%\n",
      "==================================================\n",
      "‚úÖ IDENTITY VERIFIED - Same person detected!\n"
     ]
    }
   ],
   "source": [
    "# test_identity_onnx.py\n",
    "import cv2\n",
    "from models.identity_verifier_onnx import IdentityVerifierONNX\n",
    "from models.liveness_model import LivenessDetector\n",
    "from utils.config import IDENTITY_MODEL, LIVENESS_MODEL\n",
    "\n",
    "print(\"Loading models...\")\n",
    "verifier = IdentityVerifierONNX(IDENTITY_MODEL)\n",
    "liveness = LivenessDetector(LIVENESS_MODEL)\n",
    "\n",
    "print(\"\\n‚úÖ Webcam test: Take 2 photos of yourself\")\n",
    "print(\"Press 'C' to capture first photo\")\n",
    "print(\"Press 'C' again to capture second photo\")\n",
    "print(\"Press 'Q' to quit\\n\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "photos = []\n",
    "\n",
    "while len(photos) < 2:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Detect face\n",
    "    live_result = liveness.predict(frame)\n",
    "    \n",
    "    # Draw box\n",
    "    if live_result['face_detected']:\n",
    "        bbox = live_result['bbox']\n",
    "        cv2.rectangle(frame, tuple(bbox[0]), tuple(bbox[1]), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"Photo {len(photos) + 1}/2 - Press 'C'\", \n",
    "                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow(\"Identity Verification Test\", frame)\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('c') and live_result['face_detected']:\n",
    "        # Capture face crop\n",
    "        bbox = live_result['bbox']\n",
    "        face_crop = frame[bbox[0][1]:bbox[1][1], bbox[0][0]:bbox[1][0]]\n",
    "        photos.append(face_crop)\n",
    "        print(f\"‚úÖ Captured photo {len(photos)}\")\n",
    "    elif key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "if len(photos) == 2:\n",
    "    print(\"\\nüîç Verifying identity...\")\n",
    "    result = verifier.verify_identity(photos[0], photos[1], threshold=0.70)\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Match Score: {result['match_score']:.2%}\")\n",
    "    print(f\"Same Person: {result['is_same_person']}\")\n",
    "    print(f\"Threshold: {result['threshold_used']:.0%}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    if result['is_same_person']:\n",
    "        print(\"‚úÖ IDENTITY VERIFIED - Same person detected!\")\n",
    "    else:\n",
    "        print(\"‚ùå IDENTITY MISMATCH - Different person or poor quality!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Test cancelled or insufficient photos captured\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "124e6e79-b099-4f8d-8915-f91993cc59be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "‚úÖ DeepfakeDetector loaded on cpu with Grad-CAM explainability\n",
      "‚úÖ LivenessDetector loaded (DeepPixBiS - Optimized)\n",
      "‚úÖ IdentityVerifierONNX loaded (InceptionResnetV1)\n",
      "‚úÖ All models loaded\n",
      "\n",
      "Controls:\n",
      "  'R' - Register reference face (for identity matching)\n",
      "  'Q' - Quit\n",
      "--------------------------------------------------\n",
      "‚úÖ Reference face registered!\n",
      "‚úÖ Reference face registered!\n",
      "\n",
      "‚úÖ Demo closed\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Real-time eKYC demo with all components\n",
    "Run: python realtime_demo.py\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from models.deepfake_model import DeepfakeDetector\n",
    "from models.liveness_model import LivenessDetector\n",
    "from models.identity_verifier_onnx import IdentityVerifierONNX\n",
    "from config import *\n",
    "\n",
    "# Load models\n",
    "print(\"Loading models...\")\n",
    "deepfake = DeepfakeDetector(DEEPFAKE_MODEL, device=DEVICE)\n",
    "liveness = LivenessDetector(LIVENESS_MODEL)\n",
    "identity = IdentityVerifierONNX(IDENTITY_MODEL, use_gpu=(DEVICE=='cuda'))\n",
    "\n",
    "print(\"‚úÖ All models loaded\\n\")\n",
    "print(\"Controls:\")\n",
    "print(\"  'R' - Register reference face (for identity matching)\")\n",
    "print(\"  'Q' - Quit\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "\n",
    "# FPS tracking\n",
    "fps_history = []\n",
    "reference_embedding = None\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    start_time = cv2.getTickCount()\n",
    "    canvas = frame.copy()\n",
    "    h, w = canvas.shape[:2]\n",
    "    \n",
    "    # Liveness detection\n",
    "    live_result = liveness.predict(frame)\n",
    "    \n",
    "    if live_result['face_detected']:\n",
    "        bbox = live_result['bbox']\n",
    "        face_crop = frame[bbox[0][1]:bbox[1][1], bbox[0][0]:bbox[1][0]]\n",
    "        \n",
    "        # Deepfake detection\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        deep_result = deepfake.predict(frame_rgb)\n",
    "        \n",
    "        # Identity verification (if reference registered)\n",
    "        identity_matched = False\n",
    "        match_score = 0.0\n",
    "        \n",
    "        if reference_embedding is not None and face_crop.size > 0:\n",
    "            current_embedding = identity.get_embedding(face_crop)\n",
    "            if current_embedding is not None:\n",
    "                match_score = identity.compute_similarity(reference_embedding, current_embedding)\n",
    "                identity_matched = match_score >= 0.70\n",
    "        \n",
    "        # Overall verification\n",
    "        verified = (\n",
    "            deep_result['prediction'] == 'REAL' and\n",
    "            live_result['is_live'] and\n",
    "            (reference_embedding is None or identity_matched)\n",
    "        )\n",
    "        \n",
    "        # Draw bounding box\n",
    "        color = (0, 255, 0) if verified else (0, 0, 255)\n",
    "        cv2.rectangle(canvas, tuple(bbox[0]), tuple(bbox[1]), color, 3)\n",
    "        \n",
    "        # Status overlay\n",
    "        status_text = \"‚úì VERIFIED\" if verified else \"‚úó REJECTED\"\n",
    "        cv2.putText(canvas, status_text, (10, 40),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 3)\n",
    "        \n",
    "        # Detailed info - ‚ö†Ô∏è FIX: Use 'real_probability' instead of 'confidence'\n",
    "        y_offset = 80\n",
    "        cv2.putText(canvas, f\"Deepfake: {deep_result['prediction']} ({deep_result['real_probability']:.1%})\",\n",
    "                   (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        y_offset += 30\n",
    "        \n",
    "        cv2.putText(canvas, f\"Liveness: {live_result['score']:.3f} {'‚úì' if live_result['is_live'] else '‚úó'}\",\n",
    "                   (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        y_offset += 30\n",
    "        \n",
    "        if reference_embedding is not None:\n",
    "            cv2.putText(canvas, f\"Identity: {match_score:.2%} {'‚úì' if identity_matched else '‚úó'}\",\n",
    "                       (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        else:\n",
    "            cv2.putText(canvas, \"Identity: No reference (Press 'R')\",\n",
    "                       (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 165, 0), 2)\n",
    "    \n",
    "    # FPS calculation\n",
    "    elapsed = (cv2.getTickCount() - start_time) / cv2.getTickFrequency()\n",
    "    fps = 1.0 / elapsed if elapsed > 0 else 0\n",
    "    fps_history.append(fps)\n",
    "    if len(fps_history) > 30:\n",
    "        fps_history.pop(0)\n",
    "    \n",
    "    avg_fps = np.mean(fps_history)\n",
    "    cv2.putText(canvas, f\"FPS: {avg_fps:.1f}\", \n",
    "               (w - 150, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "    \n",
    "    cv2.imshow(\"eKYC Real-time Demo\", canvas)\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('r') and live_result['face_detected']:\n",
    "        # Register reference face\n",
    "        bbox = live_result['bbox']\n",
    "        face_crop = frame[bbox[0][1]:bbox[1][1], bbox[0][0]:bbox[1][0]]\n",
    "        reference_embedding = identity.get_embedding(face_crop)\n",
    "        if reference_embedding is not None:\n",
    "            print(\"‚úÖ Reference face registered!\")\n",
    "        else:\n",
    "            print(\"‚ùå Failed to register face\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"\\n‚úÖ Demo closed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17e30873-0e03-486b-bcdc-16a32a61aeeb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DeepfakeDetector' from 'models.deepfake_model' (C:\\Users\\hp\\Saved Games\\ekyc_system\\models\\deepfake_model.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mTest enhanced explainability system\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeepfake_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeepfakeDetector\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menhanced_explainability\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EnhancedExplainability\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfrequency_analyzer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FrequencyAnalyzer\n",
      "File \u001b[1;32m~\\Saved Games\\ekyc_system\\models\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mModels package\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeepfake_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeepfakeDetector, MultiTaskDeepfakeDetector\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mliveness_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LivenessDetector\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeepfakeDetector\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultiTaskDeepfakeDetector\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLivenessDetector\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'DeepfakeDetector' from 'models.deepfake_model' (C:\\Users\\hp\\Saved Games\\ekyc_system\\models\\deepfake_model.py)"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test enhanced explainability system\n",
    "\"\"\"\n",
    "\n",
    "from PIL import Image\n",
    "from models.deepfake_model import DeepfakeDetector\n",
    "from models.enhanced_explainability import EnhancedExplainability\n",
    "from frequency_analyzer import FrequencyAnalyzer\n",
    "from explainability_dashboard import save_dashboard_report\n",
    "from config import DEEPFAKE_MODEL, DEVICE\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ENHANCED EXPLAINABILITY TEST\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Load models\n",
    "print(\"Loading models...\")\n",
    "base_detector = DeepfakeDetector(DEEPFAKE_MODEL, device=DEVICE)\n",
    "enhanced_detector = EnhancedExplainability(base_detector)\n",
    "frequency = FrequencyAnalyzer(device='cpu')\n",
    "print()\n",
    "\n",
    "# Load test image\n",
    "test_img_path = input(\"Enter path to test image (or press Enter for webcam capture): \").strip()\n",
    "\n",
    "if not test_img_path:\n",
    "    # Capture from webcam\n",
    "    import cv2\n",
    "    print(\"\\nüì∑ Opening webcam... Press 'C' to capture, 'Q' to quit\")\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        cv2.putText(frame, \"Press 'C' to capture image\", (10, 30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        cv2.imshow(\"Capture Test Image\", frame)\n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('c'):\n",
    "            test_img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            print(\"‚úÖ Image captured!\")\n",
    "            break\n",
    "        elif key == ord('q'):\n",
    "            print(\"‚ùå Cancelled\")\n",
    "            exit()\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    test_img = Image.open(test_img_path)\n",
    "\n",
    "print(\"\\nüîç Running enhanced analysis...\\n\")\n",
    "\n",
    "# Run predictions\n",
    "pred = enhanced_detector.predict_with_enhanced_explainability(test_img)\n",
    "freq = frequency.analyze_deepfake_frequency(test_img)\n",
    "\n",
    "# Print results\n",
    "print(\"=\"*60)\n",
    "print(f\"VERDICT: {pred['prediction']}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nAuthenticity:\")\n",
    "print(f\"  Real Probability: {pred['real_probability']:.1%}\")\n",
    "print(f\"  Fake Probability: {pred['fake_probability']:.1%}\")\n",
    "\n",
    "if pred['prediction'] == 'FAKE':\n",
    "    print(f\"\\nForgery Analysis:\")\n",
    "    print(f\"  Type: {pred['forgery_type']}\")\n",
    "    print(f\"  Description: {pred['forgery_description']}\")\n",
    "    print(f\"  Confidence: {pred['forgery_confidence']:.1%}\")\n",
    "\n",
    "if pred['suspicious_regions']:\n",
    "    print(f\"\\nSuspicious Regions Detected:\")\n",
    "    for region in pred['suspicious_regions']:\n",
    "        print(f\"  ‚Ä¢ {region['region']}: {region['confidence']:.1f}% activation\")\n",
    "\n",
    "if freq['is_suspicious']:\n",
    "    print(f\"\\nFrequency Anomalies:\")\n",
    "    print(f\"  Anomaly Score: {freq['anomaly_score']:.1%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Generate and save dashboard\n",
    "print(\"\\nüìä Generating visual report...\")\n",
    "dashboard = save_dashboard_report(test_img, pred, \"enhanced_report.png\", freq)\n",
    "dashboard.show()\n",
    "\n",
    "print(\"\\n‚úÖ Test complete!\")\n",
    "print(\"Report saved to: enhanced_report.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69b7006b-8654-4b50-9eed-f489402c01f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading liveness detector...\n",
      "‚úÖ LivenessDetector loaded\n",
      "‚úÖ Press 'Q' to quit\n",
      "‚úÖ Liveness threshold: >0.03 (GitHub standard)\n",
      "\n",
      "Face: True | Live: False | Score: 0.2329 | FPS: 0.4\n",
      "Face: True | Live: False | Score: 0.1205 | FPS: 0.7\n",
      "Face: True | Live: True | Score: 0.5592 | FPS: 0.9\n",
      "Face: True | Live: False | Score: 0.0138 | FPS: 1.1\n",
      "Face: True | Live: False | Score: 0.0180 | FPS: 1.3\n",
      "Face: False | Live: False | Score: 0.0000 | FPS: 1.6\n",
      "Face: False | Live: False | Score: 0.0000 | FPS: 1.8\n",
      "Face: False | Live: False | Score: 0.0000 | FPS: 2.1\n",
      "Face: False | Live: False | Score: 0.0000 | FPS: 2.3\n",
      "Face: False | Live: False | Score: 0.0000 | FPS: 2.5\n",
      "Face: False | Live: False | Score: 0.0000 | FPS: 2.7\n",
      "Face: False | Live: False | Score: 0.0000 | FPS: 2.9\n",
      "Face: False | Live: False | Score: 0.0000 | FPS: 3.2\n",
      "Face: True | Live: False | Score: 0.0127 | FPS: 3.2\n",
      "Face: True | Live: False | Score: 0.1534 | FPS: 3.2\n",
      "Face: True | Live: False | Score: 0.0978 | FPS: 3.2\n",
      "Face: True | Live: False | Score: 0.0877 | FPS: 3.2\n",
      "Face: True | Live: False | Score: 0.0799 | FPS: 3.2\n",
      "Face: True | Live: False | Score: 0.0220 | FPS: 3.2\n",
      "Face: True | Live: False | Score: 0.0147 | FPS: 3.2\n",
      "Face: True | Live: True | Score: 0.6781 | FPS: 3.2\n",
      "Face: True | Live: True | Score: 0.8710 | FPS: 3.2\n",
      "Face: True | Live: True | Score: 0.8615 | FPS: 3.2\n",
      "Face: True | Live: True | Score: 0.9312 | FPS: 3.2\n",
      "Face: True | Live: True | Score: 0.8915 | FPS: 3.2\n",
      "Face: True | Live: True | Score: 0.9221 | FPS: 3.2\n",
      "Face: True | Live: True | Score: 0.7434 | FPS: 3.2\n",
      "Face: True | Live: True | Score: 0.9561 | FPS: 3.2\n",
      "Face: True | Live: True | Score: 0.8648 | FPS: 3.2\n",
      "Face: True | Live: True | Score: 0.9759 | FPS: 3.2\n",
      "Face: True | Live: True | Score: 0.9889 | FPS: 3.3\n",
      "Face: True | Live: True | Score: 0.9424 | FPS: 3.3\n",
      "Face: True | Live: True | Score: 0.8886 | FPS: 3.3\n",
      "Face: True | Live: True | Score: 0.9437 | FPS: 3.3\n",
      "Face: True | Live: True | Score: 0.8841 | FPS: 3.3\n",
      "Face: True | Live: True | Score: 0.8508 | FPS: 3.3\n",
      "Face: True | Live: True | Score: 0.8403 | FPS: 3.3\n",
      "Face: True | Live: True | Score: 0.6150 | FPS: 3.3\n",
      "Face: True | Live: True | Score: 0.6393 | FPS: 3.3\n",
      "Face: True | Live: False | Score: 0.1206 | FPS: 3.3\n",
      "Face: True | Live: False | Score: 0.2073 | FPS: 3.3\n",
      "Face: True | Live: False | Score: 0.3058 | FPS: 3.3\n",
      "Face: True | Live: True | Score: 0.7788 | FPS: 3.3\n",
      "Face: True | Live: False | Score: 0.3035 | FPS: 3.3\n",
      "Face: True | Live: True | Score: 0.7036 | FPS: 3.3\n",
      "Face: True | Live: True | Score: 0.5966 | FPS: 3.3\n",
      "Face: True | Live: True | Score: 0.6545 | FPS: 3.3\n",
      "Face: True | Live: True | Score: 0.8846 | FPS: 3.3\n",
      "Face: True | Live: True | Score: 0.8525 | FPS: 3.3\n",
      "Face: True | Live: True | Score: 0.9241 | FPS: 3.3\n",
      "Face: True | Live: True | Score: 0.9074 | FPS: 3.3\n",
      "Face: True | Live: True | Score: 0.8896 | FPS: 3.3\n",
      "Face: True | Live: True | Score: 0.9360 | FPS: 3.3\n",
      "Face: True | Live: True | Score: 0.7847 | FPS: 3.3\n",
      "Face: True | Live: True | Score: 0.7130 | FPS: 3.3\n",
      "Face: True | Live: True | Score: 0.7827 | FPS: 3.3\n",
      "Face: True | Live: True | Score: 0.9119 | FPS: 3.3\n",
      "Face: True | Live: True | Score: 0.8449 | FPS: 3.3\n"
     ]
    }
   ],
   "source": [
    "# test_liveness_fix.py\n",
    "import cv2\n",
    "from models.liveness_model import LivenessDetector\n",
    "from config import LIVENESS_MODEL\n",
    "\n",
    "print(\"Loading liveness detector...\")\n",
    "detector = LivenessDetector(LIVENESS_MODEL)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "print(\"‚úÖ Press 'Q' to quit\")\n",
    "print(\"‚úÖ Liveness threshold: >0.03 (GitHub standard)\\n\")\n",
    "\n",
    "frame_count = 0\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    result = detector.predict(frame)\n",
    "    frame_count += 1\n",
    "    \n",
    "    # Calculate FPS\n",
    "    elapsed = time.time() - start_time\n",
    "    fps = frame_count / elapsed if elapsed > 0 else 0\n",
    "    \n",
    "    print(f\"Face: {result['face_detected']} | Live: {result['is_live']} | \"\n",
    "          f\"Score: {result['score']:.4f} | FPS: {fps:.1f}\")\n",
    "    \n",
    "    if result['face_detected']:\n",
    "        bbox = result['bbox']\n",
    "        color = (0, 255, 0) if result['is_live'] else (0, 0, 255)\n",
    "        cv2.rectangle(frame, tuple(bbox[0]), tuple(bbox[1]), color, 2)\n",
    "        \n",
    "        text = f\"{'LIVE' if result['is_live'] else 'SPOOF'} ({result['score']:.4f})\"\n",
    "        cv2.putText(frame, text, (bbox[0][0], bbox[0][1] - 10),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        \n",
    "        # Add FPS counter\n",
    "        cv2.putText(frame, f\"FPS: {fps:.1f}\", (10, 30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "    \n",
    "    cv2.imshow(\"Liveness Test\", frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c3f5dd-1eed-4675-b35d-5ff81dd8a348",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
